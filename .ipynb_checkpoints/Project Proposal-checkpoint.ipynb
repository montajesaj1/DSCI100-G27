{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "fEU79KbQe30VUPlKHy0w3X",
     "type": "MD"
    }
   },
   "source": [
    "# DSCI 100: Project Proposal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "RqSSpC8YMDYXA0AGtFSzue",
     "type": "CODE"
    },
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): attempt to use zero-length variable name\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): attempt to use zero-length variable name\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# libraries \n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(gridExtra)\n",
    "options(repr.matrix.max.rows = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "\n",
    "Auditing is the examination of businesses financial records and the inspection that they align with standard accounting laws and principles (Hooda, 2018). Certain factors of a business or firm, such as historical discrepancy between a financial report and an audit inspection can help auditors identify those that are higher risk for fraudulent activity. This dataset contains information about 777 firms, each of which are either classified as “Fraud” firms, or “Non-fraud” firms. \n",
    "\n",
    "The dataset aims to aid in the auditing process, by providing insight into whether a particular firm is “high risk” (in which case auditors would want to visit the firm) or “low risk” (in which case auditors may skip visiting that firm). Some of the risk factors examined in the dataset include discrepancies in reports, historical discrepancy scores, and amounts of money involved in misstatements. With this dataset, we will implement a K-nearest-neighbors classification model to identify \"Fraud\" firms from unseen datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "TJ3ujE2qIVRnwcgNcKiDR3",
     "type": "MD"
    }
   },
   "source": [
    "### 2. Preliminary EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Descriptions\n",
    "\n",
    "| -**Inherent risk factors**- |                                                                                               | -**Control risk factors**- |                                                                                     |\n",
    "|-----------------------|-----------------------------------------------------------------------------------------------------|----------------------|-------------------------------------------------------------------------------------------|\n",
    "| **Feature**           | Information                                                                                         | **Feature**          | Information                                                                               |\n",
    "| Para A value          | Discrepancy found in the planned-expenditure of inspection and summary report A in Rs (in crore).   | Sector score         | Historical risk score value of the target-unit in the Table 1 using analytical procedure. |\n",
    "| Para B value          | Discrepancy found in the unplanned-expenditure of inspection and summary report B in Rs (in crore). | Loss                 | Amount of loss suffered by the firm last year.                                            |\n",
    "| Total                 | Total amount of discrepancy found in other reports Rs (in crore).                                   | History              | Average historical loss suffered by firm in the last 10¬†years.                           |\n",
    "| Number                | Historical discrepancy score.                                                                       | District score       | Historical risk score of a district in the last 10¬†years.                                |\n",
    "| Money value           | Amount of money involved in misstatements in the past audits.                                       |                      |                                                                                           |\n",
    "| **Other features**    |                                                                                                     |                      |                                                                                           |\n",
    "| **Feature**           | Information                                                                                         | **Feature**          | Information                                                                               |\n",
    "| Sector ID             | Unique ID of the target sector.                                                                     | Location ID          | Unique ID of the city/province.                                                           |\n",
    "| ARS                   | Total risk score using analytical procedure.                                                        | Audit ID             | Unique Id assigned to an audit case.                                                      |\n",
    "| Risk class            | Risk Class assigned to an audit-case. (Target Feature)                                              |                      |                                                                                           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "arcoO8ygL1jTE4qGnY6KoN",
     "type": "CODE"
    },
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "audit <- read_csv(\"audit_data/audit_risk.csv\") \n",
    "audit <- audit |> mutate(Risk = as.factor(Risk), LOCATION_ID = as.factor(LOCATION_ID))\n",
    "head(audit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tidying the Data\n",
    "\n",
    "audit_tidy <- audit |>\n",
    "  pivot_longer(cols = starts_with(\"PARA_\"), names_to = \"discrepancy\", values_to = \"discrepancy_value\") |>\n",
    "  pivot_longer(cols = starts_with(\"Score_\"), names_to = \"score_variable\", values_to = \"score_value\") |>\n",
    "  pivot_longer(cols = starts_with(\"Risk_\"), names_to = \"risk_variable\", values_to = \"risk_value\")\n",
    "\n",
    "head(audit_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(audit_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "risk_split <- initial_split(audit_tidy, prop = 0.75, strata = Risk)\n",
    "risk_train <- training(risk_split)\n",
    "risk_test <- testing(risk_split) \n",
    "\n",
    "head(risk_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): attempt to use zero-length variable name\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): attempt to use zero-length variable name\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "feature_plot1 <- risk_train |> ggplot(aes(x = TOTAL, y = Inherent_Risk, color = Risk)) + geom_point() + scale_x_log10() + scale_y_log10() +\n",
    "    ggtitle('Scatter Plot of TOTAL vs Inherent Risk') +\n",
    "    xlab('TOTAL') +\n",
    "    ylab('Inherent Risk')\n",
    "\n",
    "feature_plot2 <- ggplot(risk_train, aes(x = TOTAL, y = Money_Value)) +\n",
    "  geom_point(aes(color = Risk), alpha = 0.5) +\n",
    "  scale_x_log10() + scale_y_log10() +\n",
    "  ggtitle('Scatter Plot of TOTAL vs Money_Value') +\n",
    "  xlab('TOTAL') +\n",
    "  ylab('Money_Value')\n",
    "\n",
    "\n",
    "feature_plot3 <- risk_train |>\n",
    "  group_by(LOCATION_ID, Risk) |>\n",
    "  summarise(count = n(), .groups = \"drop\") |>\n",
    "  group_by(LOCATION_ID) |>\n",
    "  summarise(total = sum(count), most_frequent_risk = Risk[which.max(count)]) |>\n",
    "  ungroup() |>\n",
    "  mutate(LOCATION_ID = reorder(LOCATION_ID, -total)) |>\n",
    "  ggplot(aes(y = LOCATION_ID, x = total, fill = most_frequent_risk)) +\n",
    "    geom_bar(stat = \"identity\", position = \"dodge\") +\n",
    "    ggtitle(\"Bar Chart of Location ID by Risk\") +\n",
    "    ylab(\"Location ID\") +\n",
    "    xlab(\"Count\") \n",
    "\n",
    "\n",
    "feature_plot4 <- risk_train |>\n",
    "  ggplot(aes(y = score_value, x = score_variable, fill = Risk)) +\n",
    "    geom_bar(stat = \"identity\", position = \"stack\") +\n",
    "    ggtitle(\"Bar Chart of Score Variables by Score Values\") +\n",
    "    ylab(\"Score Values\") +\n",
    "    xlab(\"Score Variables\") \n",
    "\n",
    "\n",
    "grid.arrange(feature_plot1, feature_plot2, feature_plot3, feature_plot4, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "nvslsIDT062r9VXRYjCa5r",
     "type": "MD"
    }
   },
   "source": [
    "### 3. Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the K-nearest neighbour algorithm to build the classifier for our data. We want to find the number of neighbours that will give us the most accurate classification results. By first splitting the data into a training set and a test set, we can then split the training data into a sub training set and a validation set in order to perform a cross validation. Following this we will create a recipe that selects Risk as our class and ___, ____, ____, and ___ as our predictors and standardize the training data. When creating our model using the KNN algorithm, we will set neighbours = tune() so that our cross validation can calculate an accuracy for multiple values of K. We will combine this model with the recipe into a workflow to train the classifier. We will visualize the results (which number of neighbours is appropraite) by plotting the accuracy estimates against the number of neighbors. When building our K nearest neighbours classifier for the dataset, we will use the number of neighbours will give us the most accurate predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "LMI8NBq4QOo4pfp1ZnhwA9",
     "type": "MD"
    }
   },
   "source": [
    "### 4. Expected Outcomes and Significance "
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "minimal",
   "computation_mode": "JUPYTER",
   "package_manager": "conda",
   "packages": [],
   "report_row_ids": [],
   "version": 3
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  },
  "name": "Project Proposal.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
